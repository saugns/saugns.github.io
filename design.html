<!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Strict//EN' 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd'>
<html xmlns='http://www.w3.org/1999/xhtml'>
<head>
	<meta http-equiv='Content-Type' content='text/html; charset=UTF-8' />
	<meta name='description'
content="Design of the saugns program and SAU language." />
	<meta name='keywords'
content="saugns, SAU language, Scriptable AUdio, software design" />
	<link rel='stylesheet' href='style.css' type='text/css' title='Default' /><style type='text/css'>@import url("style.css");</style>
<title>Design and main ideas</title>
</head>
<body>
<p><i>Back to <a href='index.html'>main page</a>.</i>
</p>
<h1>Design and main ideas</h1>
<p>Notes on the design of the <a href='index.html'>saugns software (and SAU language)</a>, as it has evolved, and the main ideas involved. (The SAU language has evolved in parallel with the software implementing it.)
</p>
<ul>
<li><a href='#roots'>Roots: Early 2011 design</a><ul>
	<li><a href='#roots-timing'>Timing when running and generating</a></li>
	<li><a href='#roots-limits'>Limitations of the early design</a></li>
	</ul>
</li>
<li><a href='#trunk'>Trunk: Experimentation and 2012 ideas</a><ul>
	<li><a href='#trunk-growing'>Growing the early design</a></li>
	<li><a href='#trunk-oddsends'>Odds and ends from clean-up work</a></li>
	</ul>
</li>
</ul>
<h2 id='roots'>Roots: Early 2011 design</h2>
<p>The program was developed from scratch, the language starting out as something simple enough for a trivial program to interpret.
</p>
<p>If a single big letter (<code>W</code>) is used to start a wave oscillator, and a small letter followed by a number gives it a value for frequency (<code>f</code>), amplitude (<code>a</code>), or time duration (<code>t</code>), then parsing is trivial. No abstractions for lexing or syntax trees, etc., are necessary. For each oscillator, the parser can simply add a node to a list, and set values for the current node according to any parameter assignments which follow for that oscillator. After parsing is done, the resulting list of nodes specifies what to run and generate.
</p>
<p>The list of nodes can be viewed as a sequential list of "events" to handle, which is basically the same as a list of instructions to follow in a program. To run it all, the list needs to be examined once to figure out what objects need to be allocated and prepared, and a second time when actually running the "program" it constitutes.
</p>
<p>Supporting nested lists in the parser and generator allows implementing modulation techniques, with the language extended to allow a list of oscillators to do something with the frequency, phase, amplitude, etc., of an oscillator to which the list is assigned. A touch of recursion, and this is a simple-enough extension; time proceeds along a linear list like before, though the data used in connection with each node may branch out.
</p>
<p>The big eventual problem is that the complexity of keeping it working explodes exponentially as language features for greater expressiveness are added on top of the simple core. (This is best solved by gracefully complicating the simple core with further processing stages to scale better.) But long before that turns into a problem, in small and tidy ways it's very possible to support nice things like parallel audio generation (several "voices"), combined with a sequential "time separator", and a more flexible "insert time delay for what's placed after this" modifier.
</p>
<p>That kind of terse and simple language which a fairly trivial program can run may be ideal for a flexible tone generator language. But there's a great, huge chasm between that and a powerful musical language.
</p>
<h3 id='roots-timing'>Timing when running and generating</h3>
<p>Time for a script begins at 0 ms. A script is translated into a list of timed updates, or "events", each new event taking place after the previous. Each event configures the system, e.g. telling it to start generating something. (Some events take place 0 ms after the previous, making them simultaneous. The change brought by each new simultaneous event is applied on top of the previous state before time proceeds.)
</p>
<p>The running of a script advances through time, primarily, and in turn the list of events, secondarily. Time proceeds as output samples are written, and after translation from ms is measured in the number of samples. Events, on the other hand, only come with time and do not advance it. But events take priority over output generation in time, pausing it while the events are handled.
</p>
<p>Each thing which generates output, such as a wave oscillator, has a time duration of use. Thus, its output will begin at a time position and end at another time position. The script has ended when no things remain in use, and no further events remain to be waited for (in sound or in quiet).
</p>
<h3 id='roots-limits'>Limitations of the early design</h3>
<p>Some functionality cannot be reached without complicating the core design and beginning to move beyond it.
</p>
<p>Early on, the capabilities of old FM synthesizer systems had been an inspiration, but it was seen that they support connecting oscillators in arrangements other than the tree structures of carriers and modulators provided for by nested lists; e.g. several carriers may share a modulator, and in general the oscillator connection schema is a DAG (directed acyclic graph) in Yamaha's old FM "algorithms". (Technically, self-modulation could however be viewed as addding self-loops to an otherwise acyclic graph.)
</p>
<p>Among ideas not implemented in the early program, mostly it isn't audio generation features which suggest great departures in design, however. Mostly, it is programming language ideas, like defining and using functions for creating sounds, or other ways of turning audio definitions entered in a script into a "template" of sorts for further audio in that script, and other ideas increasing language expressiveness.
</p>
<p>Relative to the early language, some kinds of extensions for it would mainly require complicating the design closer to the parsing end of the program, while others require reworking the other end which ultimately runs stuff into Turing complete capability (from something far more limited). I mainly focused on the former, on the way into further experimenting.
</p>
<h2 id='trunk'>Trunk: Experimentation and 2012 ideas</h2>
<p>Experimenting on in 2011 and beyond, and also researching potentially useful ideas for programming languages and compilers in 2012, led to a series of <a href='ideas2012.html'>old notes</a>. Mainly, a list of thoughts on a new language, and ideas for possible design elaborations. But the gap between theory in the abstract, and seeing how whatever has been done in practice maps to it, was great for me back then; I was too blinded by differences in appearance. In later years, I can recover the understanding of my own early work and understand fancier theory at the same time.
</p>
<p>Various good little ideas made it into the program design in the year between April 2011 and April 2012 (when the old work ended), but in a rough and sometimes buggy form, requiring later clean-up. Various things towards which first steps were taken were also left unfinished.
</p>
<p>Ideas from 2012, and later, remain to be explored more thoroughly for extending and reworking features.
</p>
<h3 id='trunk-growing'>Growing the early design</h3>
<p>In April 2011, the simple structures used as parser output and input for audio generation were cleaner than a year later. They consisted of a main, flat linked list of nodes from the parser, and additional fields making it possible to traverse it and handle the data in other ways, when nested script content had resulted in the sequence of nodes.
</p>
<p>The April 2012 program, though messier, had however brought a good compromise in principle between those structures and a normal "syntax tree", by making a tree in the parser when nesting is used, but keeping the nodes used equally "fat" (e.g. one node per oscillator definition, not one node for every parameter or value). Post-parse code can later translate that structure into something more flat and better-suited for the ultimate use.
</p>
<p>A syntax extension part of the early design makes use of an extra type of node nesting, flattened away after parsing. "Composite events" allow timing to be structured differently in a script. The idea is to group a series of changes for a single object (e.g. an oscillator) in one place, each change taking place after the time duration used for the previous, making the whole look like one big event composed of sub-events. This allows updates to several objects in a part of the script to be grouped per object, instead of having to intersperse changes for different objects according to the script-wide flow of time.
</p>
<p>A middle-layer between the parsing end and the audio generation end of the program had come along by 2012, initially from moving out such semantic handling from the parser after it became overgrown. This middle developed to track timing, and count and allocate voices for sound generation prior to running it. (Some of the limitations of the language allow time durations in a script to be pre-calculated without running the script; the language is not Turing complete.)
</p>
<h3 id='trunk-oddsends'>Odds and ends from clean-up work</h3>
<p>Some general ideas have evolved since reviving the project in November 2017, concerning making and keeping it cleaner and more modular. Small-scale experiments in how to (re)structure or otherwise improve little pieces of the whole have taken a large part of the focus as of November 2020, in a slow-going pedantic clean-up phase for the project. (It's not pragmatic at all, but it's been a good-enough way to spend time in a glum period of life.)
</p>
<p>To be continued...
</p>
</body>
</html>
